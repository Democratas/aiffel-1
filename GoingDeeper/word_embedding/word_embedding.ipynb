{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T23:31:40.028915Z",
     "start_time": "2024-07-03T23:31:40.027472Z"
    }
   },
   "cell_type": "code",
   "source": "# !pip install konlpy",
   "id": "825bf35070599110",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T23:31:54.524032Z",
     "start_time": "2024-07-03T23:31:54.490272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "print(\"임포트 완료\")"
   ],
   "id": "b70b06f06c7384e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임포트 완료\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T23:31:57.937405Z",
     "start_time": "2024-07-03T23:31:57.932787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"임금님 귀는 당나귀 귀! 임금님 귀는 당나귀 귀! 실컷~ 소리치고 나니 속이 확 뚫려 살 것 같았어.\"\n",
    "text"
   ],
   "id": "f1cce3514e3aa24a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'임금님 귀는 당나귀 귀! 임금님 귀는 당나귀 귀! 실컷~ 소리치고 나니 속이 확 뚫려 살 것 같았어.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f8dacc1ff4b5b6a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 영어 Word2Vec 실습과 OOV 문제",
   "id": "da358d7b80dd8542"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "영어 Word2Vec 실습\n",
    "----\n",
    "\n",
    "영어 데이터를 다운로드받아 직접 Word2Vec을 훈련시켜보겠습니다. Word2Vec을 별도로 구현할 필요없이 파이썬의 gensim 패키지를 통해 이미 구현된 Word2Vec 모델을 사용할 수 있습니다. 여기서 사용할 훈련 데이터는 NLTK에서 제공하는 코퍼스이며, gensim 패키지는 토픽 모델링을 위한 NLP 패키지입니다.\n",
    "\n",
    "Cloud 사용자는 이미 설치되어 있으니 아래의 명령어를 참고로만 알아두세요.\n",
    "\n",
    "    pip install nltk\n",
    "    pip install gensim"
   ],
   "id": "88b5231153743a05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T01:08:49.601457Z",
     "start_time": "2024-07-04T01:08:38.871522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "nltk.download('abc')\n",
    "nltk.download('punkt')"
   ],
   "id": "f9dd8d935d32ac8c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package abc to /Users/seongyeon/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/abc.zip.\n",
      "[nltk_data] Downloading package punkt to /Users/seongyeon/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T01:08:49.610992Z",
     "start_time": "2024-07-04T01:08:49.603861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.corpus import abc\n",
    "corpus = abc.sents()\n",
    "print(\"슝~\")"
   ],
   "id": "11ccf41dc6fa23ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T01:09:40.043661Z",
     "start_time": "2024-07-04T01:09:40.036153Z"
    }
   },
   "cell_type": "code",
   "source": "print(corpus[:3])",
   "id": "9e04fd2834eb9992",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['PM', 'denies', 'knowledge', 'of', 'AWB', 'kickbacks', 'The', 'Prime', 'Minister', 'has', 'denied', 'he', 'knew', 'AWB', 'was', 'paying', 'kickbacks', 'to', 'Iraq', 'despite', 'writing', 'to', 'the', 'wheat', 'exporter', 'asking', 'to', 'be', 'kept', 'fully', 'informed', 'on', 'Iraq', 'wheat', 'sales', '.'], ['Letters', 'from', 'John', 'Howard', 'and', 'Deputy', 'Prime', 'Minister', 'Mark', 'Vaile', 'to', 'AWB', 'have', 'been', 'released', 'by', 'the', 'Cole', 'inquiry', 'into', 'the', 'oil', 'for', 'food', 'program', '.'], ['In', 'one', 'of', 'the', 'letters', 'Mr', 'Howard', 'asks', 'AWB', 'managing', 'director', 'Andrew', 'Lindberg', 'to', 'remain', 'in', 'close', 'contact', 'with', 'the', 'Government', 'on', 'Iraq', 'wheat', 'sales', '.']]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T01:09:48.949456Z",
     "start_time": "2024-07-04T01:09:48.946895Z"
    }
   },
   "cell_type": "code",
   "source": "print('코퍼스의 크기 :',len(corpus))",
   "id": "4af91dc33e9fe5bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "코퍼스의 크기 : 29059\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T01:10:03.238879Z",
     "start_time": "2024-07-04T01:09:58.206284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(sentences = corpus, vector_size = 100, window = 5, min_count = 5, workers = 4, sg = 0)\n",
    "print(\"모델 학습 완료!\")"
   ],
   "id": "ccc5ab7cebe427b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 학습 완료!\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "위 코드에서 각 파라미터가 의미하는 바는 아래와 같습니다.\n",
    "\n",
    "- vector size = 학습 후 임베딩 벡터의 차원\n",
    "- window = 컨텍스트 윈도우 크기\n",
    "- min_count = 단어 최소 빈도수 제한 (빈도가 적은 단어들은 학습하지 않아요.)\n",
    "- workers = 학습을 위한 프로세스 수\n",
    "- sg = 0은 CBoW, 1은 Skip-gram.\n",
    "\n",
    "아주 잠깐의 기다림 끝에 Word2Vec의 학습이 완료됩니다. Word2Vec는 입력한 단어에 대해서 가장 코사인 유사도가 높은 단어들을 출력하는 model.wv.most_similar를 지원합니다. 'man'과 가장 유사한 단어들은 어떤 단어들일까요?"
   ],
   "id": "a2327532142e0f1c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T01:10:54.532210Z",
     "start_time": "2024-07-04T01:10:54.504690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_result = model.wv.most_similar(\"man\")\n",
    "print(model_result)"
   ],
   "id": "2cd6688dc5a473fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.9232221841812134), ('skull', 0.9111101627349854), ('Bang', 0.9060567021369934), ('asteroid', 0.9052808284759521), ('third', 0.9019376039505005), ('baby', 0.8993116021156311), ('dog', 0.8986425399780273), ('bought', 0.8975557088851929), ('rally', 0.8911317586898804), ('disc', 0.8890964388847351)]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T01:14:09.748198Z",
     "start_time": "2024-07-04T01:14:09.053989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model.wv.save_word2vec_format('./w2v') \n",
    "loaded_model = KeyedVectors.load_word2vec_format(\"./w2v\")\n",
    "print(\"모델  load 완료!\")"
   ],
   "id": "508871d7dd0977f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델  load 완료!\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## FastText\n",
    "- subword 단위로 쪼개서 오타에 강건함"
   ],
   "id": "d863e0231da2eb67"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T01:21:39.412744Z",
     "start_time": "2024-07-04T01:21:26.725420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.models import FastText\n",
    "fasttext_model = FastText(corpus, window=5, min_count=5, workers=4, sg=1)\n",
    "print(\"FastText 학습 완료!\")"
   ],
   "id": "51548f840b1b42b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText 학습 완료!\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T01:21:58.840179Z",
     "start_time": "2024-07-04T01:21:58.830072Z"
    }
   },
   "cell_type": "code",
   "source": "fasttext_model.wv.most_similar('overacting')",
   "id": "7f859b8380f59806",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('overwhelming', 0.9444938898086548),\n",
       " ('extracting', 0.9408138990402222),\n",
       " ('lifting', 0.9358069896697998),\n",
       " ('shooting', 0.932708740234375),\n",
       " ('tapping', 0.9303584098815918),\n",
       " ('attracting', 0.9299964904785156),\n",
       " ('contracting', 0.9287461638450623),\n",
       " ('shifting', 0.9276260137557983),\n",
       " ('emptying', 0.9275338649749756),\n",
       " ('clotting', 0.9267818331718445)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T01:22:06.894958Z",
     "start_time": "2024-07-04T01:22:06.887191Z"
    }
   },
   "cell_type": "code",
   "source": "fasttext_model.wv.most_similar('memoryy')",
   "id": "3d7cd0f65d66b8b0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('memory', 0.9551022052764893),\n",
       " ('musical', 0.8601377606391907),\n",
       " ('emotion', 0.8544632196426392),\n",
       " ('performance', 0.8536600470542908),\n",
       " ('intelligence', 0.8513544797897339),\n",
       " ('emotional', 0.8466050624847412),\n",
       " ('mess', 0.8460673689842224),\n",
       " ('flexibility', 0.8446962833404541),\n",
       " ('visual', 0.8442155122756958),\n",
       " ('cognitive', 0.8404098749160767)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Glove 실습",
   "id": "2af925a882d7c425"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T01:43:28.717812Z",
     "start_time": "2024-07-04T01:42:42.874311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gensim.downloader as api\n",
    "glove_model = api.load(\"glove-wiki-gigaword-50\")  # glove vectors 다운로드\n",
    "glove_model.most_similar(\"dog\")  # 'dog'과 비슷한 단어 찾기"
   ],
   "id": "b00481562e06be2a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cat', 0.9218006134033203),\n",
       " ('dogs', 0.8513158559799194),\n",
       " ('horse', 0.7907583117485046),\n",
       " ('puppy', 0.7754921317100525),\n",
       " ('pet', 0.7724707722663879),\n",
       " ('rabbit', 0.7720814347267151),\n",
       " ('pig', 0.7490062117576599),\n",
       " ('snake', 0.7399188876152039),\n",
       " ('baby', 0.7395570874214172),\n",
       " ('bite', 0.738793671131134)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T01:43:28.727605Z",
     "start_time": "2024-07-04T01:43:28.719338Z"
    }
   },
   "cell_type": "code",
   "source": "glove_model.most_similar('overacting')",
   "id": "ca9e503fc07c4939",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('impudence', 0.7842012047767639),\n",
       " ('puerile', 0.7816032767295837),\n",
       " ('winningly', 0.7644237279891968),\n",
       " ('grossness', 0.7576098442077637),\n",
       " ('deconstructions', 0.748936653137207),\n",
       " ('over-the-top', 0.7460805773735046),\n",
       " ('buffoonery', 0.746045708656311),\n",
       " ('impetuosity', 0.7415392994880676),\n",
       " ('sophomoric', 0.736961841583252),\n",
       " ('zaniness', 0.7353197336196899)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T01:43:28.811580Z",
     "start_time": "2024-07-04T01:43:28.728327Z"
    }
   },
   "cell_type": "code",
   "source": "glove_model.most_similar('memoryy')",
   "id": "6e42d94f8e9c26fa",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'memoryy' not present in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mglove_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmost_similar\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmemoryy\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/DL-tf/lib/python3.8/site-packages/gensim/models/keyedvectors.py:841\u001B[0m, in \u001B[0;36mKeyedVectors.most_similar\u001B[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001B[0m\n\u001B[1;32m    838\u001B[0m         weight[idx] \u001B[38;5;241m=\u001B[39m item[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    840\u001B[0m \u001B[38;5;66;03m# compute the weighted average of all keys\u001B[39;00m\n\u001B[0;32m--> 841\u001B[0m mean \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_mean_vector\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpre_normalize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpost_normalize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_missing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    842\u001B[0m all_keys \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    843\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_index(key) \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m keys \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, _KEY_TYPES) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhas_index_for(key)\n\u001B[1;32m    844\u001B[0m ]\n\u001B[1;32m    846\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m indexer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(topn, \u001B[38;5;28mint\u001B[39m):\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/DL-tf/lib/python3.8/site-packages/gensim/models/keyedvectors.py:518\u001B[0m, in \u001B[0;36mKeyedVectors.get_mean_vector\u001B[0;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001B[0m\n\u001B[1;32m    516\u001B[0m         total_weight \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mabs\u001B[39m(weights[idx])\n\u001B[1;32m    517\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ignore_missing:\n\u001B[0;32m--> 518\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKey \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m not present in vocabulary\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    520\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m total_weight \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    521\u001B[0m     mean \u001B[38;5;241m=\u001B[39m mean \u001B[38;5;241m/\u001B[39m total_weight\n",
      "\u001B[0;31mKeyError\u001B[0m: \"Key 'memoryy' not present in vocabulary\""
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "GloVe는 Word2Vec과 같이 OOV 문제를 가지고 있어서 'memoryy'라는 단어는 인식하지 못합니다. 또한 pre-trained GloVe 모델은 한글이나 알파벳 대문자가 포함된 데이터셋으로 학습하지 않았기 때문에 알파벳 소문자만 인식한다는 사실에 유의하세요!",
   "id": "6730d9b91b5240e5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
